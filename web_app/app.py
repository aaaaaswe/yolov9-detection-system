#!/usr/bin/env python3
"""
YOLOv9 å®æ—¶æ£€æµ‹ç³»ç»Ÿ - Webåº”ç”¨
åŸºäºStreamlitçš„åœ¨çº¿ç›®æ ‡æ£€æµ‹å¹³å°
"""

import streamlit as st
import cv2
import numpy as np
from PIL import Image
import os
import sys
import tempfile
import time
from pathlib import Path

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„ä»¥å¯¼å…¥æœ¬åœ°æ¨¡å—
project_root = Path(__file__).parent.parent.absolute()
sys.path.insert(0, str(project_root))

# å°è¯•å¯¼å…¥æ£€æµ‹å™¨
try:
    from detect import YOLOv9Detector
    DETECTOR_AVAILABLE = True
except ImportError as e:
    st.warning(f"è­¦å‘Š: æ— æ³•å¯¼å…¥ detect æ¨¡å—: {e}")
    st.warning("ä½¿ç”¨å†…ç½®çš„ç®€åŒ–æ£€æµ‹å™¨...")
    DETECTOR_AVAILABLE = False

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="YOLOv9 å®æ—¶æ£€æµ‹ç³»ç»Ÿ",
    page_icon="ğŸ¯",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šä¹‰CSS
st.markdown("""
    <style>
    .main {
        padding-top: 2rem;
    }
    .stAlert {
        padding: 1rem;
    }
    .uploadedFile {
        margin-bottom: 1rem;
    }
    h1 {
        color: #1f77b4;
    }
    .stButton>button {
        width: 100%;
    }
    </style>
""", unsafe_allow_html=True)


# ç®€åŒ–çš„æ£€æµ‹å™¨ç±»ï¼ˆå¤‡ç”¨ï¼‰
class SimpleDetector:
    """ç®€åŒ–çš„ YOLO æ£€æµ‹å™¨ï¼ˆå½“ detect.py ä¸å¯ç”¨æ—¶ä½¿ç”¨ï¼‰"""

    def __init__(self, weights='yolov8s.pt', conf=0.25, iou=0.45, max_det=300):
        """åˆå§‹åŒ–æ£€æµ‹å™¨"""
        from ultralytics import YOLO

        self.conf = conf
        self.iou = iou
        self.max_det = max_det

        # åŠ è½½æ¨¡å‹
        st.info(f"æ­£åœ¨åŠ è½½æ¨¡å‹: {weights}")
        self.model = YOLO(weights)

        # è·å–ç±»åˆ«åç§°ï¼ˆä½¿ç”¨ COCO æ•°æ®é›†ï¼‰
        self.class_names = self.model.names if hasattr(self.model, 'names') else [
            'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck',
            'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter',
            'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant',
            'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',
            'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite',
            'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',
            'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana',
            'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',
            'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table',
            'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',
            'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock',
            'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'
        ]

        # ç”Ÿæˆé¢œè‰²
        import random
        self.colors = [[random.randint(0, 255) for _ in range(3)] for _ in range(len(self.class_names))]

        st.success(f"æ¨¡å‹åŠ è½½æˆåŠŸ! æ£€æµ‹ç±»åˆ«: {len(self.class_names)}")


@st.cache_resource
def load_detector(weights='yolov8s.pt', conf=0.25, iou=0.45, device='cpu'):
    """åŠ è½½æ£€æµ‹å™¨ï¼ˆç¼“å­˜ï¼‰"""
    try:
        if DETECTOR_AVAILABLE:
            # ä½¿ç”¨é¡¹ç›®çš„ YOLOv9Detector
            detector = YOLOv9Detector(
                weights=weights,
                conf=conf,
                iou=iou,
                max_det=300
            )
        else:
            # ä½¿ç”¨ç®€åŒ–çš„æ£€æµ‹å™¨
            detector = SimpleDetector(
                weights=weights,
                conf=conf,
                iou=iou,
                max_det=300
            )
        return detector
    except Exception as e:
        st.error(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return None


def draw_detections(image, results, detector):
    """åœ¨å›¾åƒä¸Šç»˜åˆ¶æ£€æµ‹ç»“æœ"""
    img = image.copy()
    
    for result in results:
        boxes = result.boxes
        for box in boxes:
            # è·å–è¾¹ç•Œæ¡†åæ ‡
            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy().astype(int)
            
            # è·å–ç±»åˆ«å’Œç½®ä¿¡åº¦
            class_id = int(box.cls[0])
            conf = float(box.conf[0])
            
            # è·å–ç±»åˆ«åç§°å’Œé¢œè‰²
            class_name = detector.class_names[class_id]
            color = [tuple(int(c) for c in detector.colors[class_id])][0]
            
            # ç»˜åˆ¶è¾¹ç•Œæ¡†
            cv2.rectangle(img, (x1, y1), (x2, y2), color, 2)
            
            # ç»˜åˆ¶æ ‡ç­¾
            label = f"{class_name} {conf:.2f}"
            (label_width, label_height), _ = cv2.getTextSize(
                label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2
            )
            
            # ç»˜åˆ¶æ ‡ç­¾èƒŒæ™¯
            cv2.rectangle(
                img,
                (x1, y1 - label_height - 10),
                (x1 + label_width, y1),
                color,
                -1
            )
            
            # ç»˜åˆ¶æ ‡ç­¾æ–‡å­—
            cv2.putText(
                img,
                label,
                (x1, y1 - 5),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.5,
                (255, 255, 255),
                2
            )
    
    return img


def image_detection_page(detector):
    """å›¾ç‰‡æ£€æµ‹é¡µé¢"""
    st.header("ğŸ“· å›¾ç‰‡æ£€æµ‹")
    st.write("ä¸Šä¼ å›¾ç‰‡è¿›è¡Œç›®æ ‡æ£€æµ‹")
    
    # ä¸Šä¼ å›¾ç‰‡
    uploaded_file = st.file_uploader(
        "é€‰æ‹©ä¸€å¼ å›¾ç‰‡",
        type=['jpg', 'jpeg', 'png', 'bmp'],
        key="image_upload"
    )
    
    if uploaded_file is not None:
        # æ˜¾ç¤ºåŸå§‹å›¾ç‰‡
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("åŸå§‹å›¾ç‰‡")
            image = Image.open(uploaded_file)
            st.image(image, use_column_width=True)
        
        # æ£€æµ‹æŒ‰é’®
        if st.button("å¼€å§‹æ£€æµ‹", key="detect_image"):
            with st.spinner("æ£€æµ‹ä¸­..."):
                # ä¿å­˜ä¸´æ—¶å›¾ç‰‡
                with tempfile.NamedTemporaryFile(delete=False, suffix='.jpg') as tmp_file:
                    tmp_path = tmp_file.name
                    image.save(tmp_path)
                
                # è¯»å–å›¾ç‰‡
                img_array = np.array(image)
                if len(img_array.shape) == 2:
                    img_array = cv2.cvtColor(img_array, cv2.COLOR_GRAY2BGR)
                elif img_array.shape[2] == 4:
                    img_array = cv2.cvtColor(img_array, cv2.COLOR_RGBA2BGR)
                elif img_array.shape[2] == 3:
                    img_array = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)
                
                # æ‰§è¡Œæ£€æµ‹
                start_time = time.time()
                results = detector.model(img_array, conf=detector.conf, iou=detector.iou)
                inference_time = time.time() - start_time
                
                # ç»˜åˆ¶ç»“æœ
                annotated_img = draw_detections(img_array, results, detector)
                annotated_img_rgb = cv2.cvtColor(annotated_img, cv2.COLOR_BGR2RGB)
                
                # æ˜¾ç¤ºæ£€æµ‹ç»“æœ
                with col2:
                    st.subheader("æ£€æµ‹ç»“æœ")
                    st.image(annotated_img_rgb, use_column_width=True)
                
                # æ˜¾ç¤ºæ£€æµ‹ä¿¡æ¯
                st.success(f"æ£€æµ‹å®Œæˆ! æ¨ç†æ—¶é—´: {inference_time:.3f}ç§’")
                
                # æ˜¾ç¤ºæ£€æµ‹åˆ°çš„ç›®æ ‡
                if len(results) > 0 and len(results[0].boxes) > 0:
                    st.subheader("æ£€æµ‹ç»Ÿè®¡")
                    boxes = results[0].boxes
                    
                    # ç»Ÿè®¡å„ç±»åˆ«æ•°é‡
                    class_counts = {}
                    for box in boxes:
                        class_id = int(box.cls[0])
                        class_name = detector.class_names[class_id]
                        conf = float(box.conf[0])
                        if class_name not in class_counts:
                            class_counts[class_name] = []
                        class_counts[class_name].append(conf)
                    
                    # æ˜¾ç¤ºç»Ÿè®¡è¡¨æ ¼
                    for class_name, confidences in class_counts.items():
                        avg_conf = sum(confidences) / len(confidences)
                        st.metric(class_name, len(confidences), f"å¹³å‡ç½®ä¿¡åº¦: {avg_conf:.2f}")
                    
                    # æä¾›ä¸‹è½½
                    result_pil = Image.fromarray(annotated_img_rgb)
                    st.download_button(
                        label="ä¸‹è½½æ£€æµ‹ç»“æœ",
                        data=result_pil.tobytes(),
                        file_name=f"result_{uploaded_file.name}",
                        mime="image/jpeg"
                    )
                else:
                    st.warning("æœªæ£€æµ‹åˆ°ä»»ä½•ç›®æ ‡")
                
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                os.unlink(tmp_path)


def video_detection_page(detector):
    """è§†é¢‘æ£€æµ‹é¡µé¢"""
    st.header("ğŸ¬ è§†é¢‘æ£€æµ‹")
    st.write("ä¸Šä¼ è§†é¢‘æ–‡ä»¶è¿›è¡Œç›®æ ‡æ£€æµ‹")
    
    # ä¸Šä¼ è§†é¢‘
    uploaded_file = st.file_uploader(
        "é€‰æ‹©è§†é¢‘æ–‡ä»¶",
        type=['mp4', 'avi', 'mov', 'mkv'],
        key="video_upload"
    )
    
    if uploaded_file is not None:
        # æ˜¾ç¤ºè§†é¢‘ä¿¡æ¯
        st.info(f"æ–‡ä»¶å: {uploaded_file.name} | å¤§å°: {uploaded_file.size / 1024 / 1024:.2f} MB")
        
        # æ£€æµ‹è®¾ç½®
        col1, col2 = st.columns(2)
        with col1:
            max_frames = st.number_input("æœ€å¤§æ£€æµ‹å¸§æ•°", min_value=1, max_value=1000, value=30)
        with col2:
            skip_frames = st.number_input("è·³å¸§æ•°", min_value=0, max_value=30, value=0)
        
        # æ£€æµ‹æŒ‰é’®
        if st.button("å¼€å§‹æ£€æµ‹", key="detect_video"):
            with st.spinner("æ£€æµ‹ä¸­ï¼Œè¯·ç¨å€™..."):
                # ä¿å­˜ä¸´æ—¶è§†é¢‘
                with tempfile.NamedTemporaryFile(delete=False, suffix='.mp4') as tmp_file:
                    tmp_path = tmp_file.name
                    tmp_file.write(uploaded_file.read())
                
                # è¯»å–è§†é¢‘
                cap = cv2.VideoCapture(tmp_path)
                fps = int(cap.get(cv2.CAP_PROP_FPS))
                total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
                
                # é™åˆ¶æ£€æµ‹å¸§æ•°
                frames_to_process = min(max_frames, total_frames)
                
                # å‡†å¤‡è¾“å‡ºè§†é¢‘
                result_path = tmp_path.replace('.mp4', '_result.mp4')
                fourcc = cv2.VideoWriter_fourcc(*'mp4v')
                out = cv2.VideoWriter(result_path, fourcc, fps, 
                                      (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), 
                                       int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))))
                
                # åˆ›å»ºè¿›åº¦æ¡
                progress_bar = st.progress(0)
                frame_count = 0
                total_detections = 0
                
                while frame_count < frames_to_process:
                    ret, frame = cap.read()
                    if not ret:
                        break
                    
                    # è·³å¸§
                    if frame_count % (skip_frames + 1) != 0:
                        frame_count += 1
                        continue
                    
                    # æ£€æµ‹
                    results = detector.model(frame, conf=detector.conf, iou=detector.iou, verbose=False)
                    
                    # ç»˜åˆ¶ç»“æœ
                    annotated_frame = draw_detections(frame, results, detector)
                    out.write(annotated_frame)
                    
                    # æ›´æ–°è¿›åº¦
                    progress = (frame_count + 1) / frames_to_process
                    progress_bar.progress(progress)
                    
                    if len(results) > 0:
                        total_detections += len(results[0].boxes)
                    
                    frame_count += 1
                
                # é‡Šæ”¾èµ„æº
                cap.release()
                out.release()
                
                # æ˜¾ç¤ºç»“æœ
                st.success(f"æ£€æµ‹å®Œæˆ! å¤„ç†äº† {frame_count} å¸§ï¼Œæ£€æµ‹åˆ° {total_detections} ä¸ªç›®æ ‡")
                
                # æä¾›è§†é¢‘ä¸‹è½½
                with open(result_path, 'rb') as f:
                    st.download_button(
                        label="ä¸‹è½½æ£€æµ‹ç»“æœè§†é¢‘",
                        data=f.read(),
                        file_name=f"result_{uploaded_file.name}",
                        mime="video/mp4"
                    )
                
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                os.unlink(tmp_path)
                os.unlink(result_path)


def webcam_detection_page(detector):
    """å®æ—¶æ‘„åƒå¤´æ£€æµ‹é¡µé¢"""
    st.header("ğŸ“¹ å®æ—¶æ‘„åƒå¤´æ£€æµ‹")
    st.warning("âš ï¸ æ³¨æ„ï¼šStreamlitçš„æ‘„åƒå¤´åŠŸèƒ½éœ€è¦é¢å¤–é…ç½®ï¼Œå»ºè®®ä½¿ç”¨æœ¬åœ°Pythonè„šæœ¬è¿›è¡Œå®æ—¶æ£€æµ‹")
    
    st.info("""
    å¦‚æœéœ€è¦åœ¨ç½‘é¡µä¸Šè¿›è¡Œå®æ—¶æ‘„åƒå¤´æ£€æµ‹ï¼Œæœ‰å‡ ç§é€‰æ‹©ï¼š
    
    1. **ä½¿ç”¨æœ¬åœ°è„šæœ¬**: 
       ```bash
       python detect.py --source 0 --weights yolov8s.pt
       ```
    
    2. **ä½¿ç”¨Streamlit Cameraç»„ä»¶** (éœ€è¦æµè§ˆå™¨æƒé™):
       åœ¨æµè§ˆå™¨ä¸­è¿è¡Œï¼Œéœ€è¦HTTPSæˆ–localhost
    """)
    
    # æ£€æµ‹è®¾ç½®
    col1, col2 = st.columns(2)
    with col1:
        conf_threshold = st.slider("ç½®ä¿¡åº¦é˜ˆå€¼", 0.0, 1.0, 0.25)
    with col2:
        iou_threshold = st.slider("IOUé˜ˆå€¼", 0.0, 1.0, 0.45)
    
    # è¯´æ˜
    st.markdown("""
    ### å¦‚ä½•ä½¿ç”¨æ‘„åƒå¤´æ£€æµ‹ï¼š
    
    1. **æ–¹æ³•ä¸€ï¼šæœ¬åœ°Pythonè„šæœ¬**ï¼ˆæ¨èï¼‰
       ```bash
       cd yolov9_detection
       python detect.py --source 0 --weights yolov8s.pt --conf 0.25
       ```
       
    2. **æ–¹æ³•äºŒï¼šä½¿ç”¨WebRTC**ï¼ˆé«˜çº§ï¼‰
       éœ€è¦é¢å¤–çš„Streamlit WebRTCç»„ä»¶
    """)


def batch_detection_page(detector):
    """æ‰¹é‡æ£€æµ‹é¡µé¢"""
    st.header("ğŸ“ æ‰¹é‡å›¾ç‰‡æ£€æµ‹")
    st.write("ä¸Šä¼ å¤šå¼ å›¾ç‰‡è¿›è¡Œæ‰¹é‡æ£€æµ‹")
    
    # ä¸Šä¼ å¤šå¼ å›¾ç‰‡
    uploaded_files = st.file_uploader(
        "é€‰æ‹©å¤šå¼ å›¾ç‰‡",
        type=['jpg', 'jpeg', 'png', 'bmp'],
        accept_multiple_files=True,
        key="batch_upload"
    )
    
    if uploaded_files:
        st.info(f"å·²é€‰æ‹© {len(uploaded_files)} å¼ å›¾ç‰‡")
        
        # æ£€æµ‹æŒ‰é’®
        if st.button("å¼€å§‹æ‰¹é‡æ£€æµ‹", key="detect_batch"):
            results_container = st.container()
            
            # åˆ›å»ºè¿›åº¦æ¡
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            all_results = []
            
            for i, uploaded_file in enumerate(uploaded_files):
                status_text.text(f"æ­£åœ¨å¤„ç† {i+1}/{len(uploaded_files)}: {uploaded_file.name}")
                
                # è¯»å–å›¾ç‰‡
                image = Image.open(uploaded_file)
                img_array = np.array(image)
                
                if len(img_array.shape) == 2:
                    img_array = cv2.cvtColor(img_array, cv2.COLOR_GRAY2BGR)
                elif img_array.shape[2] == 4:
                    img_array = cv2.cvtColor(img_array, cv2.COLOR_RGBA2BGR)
                elif img_array.shape[2] == 3:
                    img_array = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)
                
                # æ£€æµ‹
                results = detector.model(img_array, conf=detector.conf, iou=detector.iou, verbose=False)
                
                # ç»˜åˆ¶ç»“æœ
                annotated_img = draw_detections(img_array, results, detector)
                annotated_img_rgb = cv2.cvtColor(annotated_img, cv2.COLOR_BGR2RGB)
                
                # ä¿å­˜ç»“æœ
                result_pil = Image.fromarray(annotated_img_rgb)
                all_results.append({
                    'name': uploaded_file.name,
                    'image': result_pil,
                    'detections': len(results[0].boxes) if len(results) > 0 else 0
                })
                
                # æ›´æ–°è¿›åº¦
                progress = (i + 1) / len(uploaded_files)
                progress_bar.progress(progress)
            
            # æ˜¾ç¤ºæ‰€æœ‰ç»“æœ
            st.success(f"æ‰¹é‡æ£€æµ‹å®Œæˆ! å¤„ç†äº† {len(uploaded_files)} å¼ å›¾ç‰‡")
            
            # åˆ†é¡µæ˜¾ç¤ºç»“æœ
            for i, result in enumerate(all_results):
                with st.expander(f"{result['name']} - æ£€æµ‹åˆ° {result['detections']} ä¸ªç›®æ ‡"):
                    col1, col2 = st.columns([2, 1])
                    
                    with col1:
                        st.image(result['image'], use_column_width=True)
                    
                    with col2:
                        # æä¾›å•å¼ ä¸‹è½½
                        st.download_button(
                            label=f"ä¸‹è½½ {result['name']}",
                            data=result['image'].tobytes(),
                            file_name=f"result_{result['name']}",
                            key=f"download_{i}",
                            mime="image/jpeg"
                        )
            
            # ä¸‹è½½æ‰€æœ‰ç»“æœï¼ˆæ‰“åŒ…ä¸ºZIPéœ€è¦é¢å¤–åº“ï¼Œæš‚æ—¶ä¸æ”¯æŒï¼‰


def resources_page():
    """é¡¹ç›®èµ„æºé¡µé¢ - å±•ç¤ºå’Œä¸‹è½½é¡¹ç›®æ–‡ä»¶"""
    st.header("ğŸ“¦ é¡¹ç›®èµ„æº")
    st.write("æŸ¥çœ‹å’Œä¸‹è½½é¡¹ç›®é…ç½®æ–‡ä»¶")
    
    # .gitignore æ–‡ä»¶å±•ç¤º
    st.subheader(".gitignore æ–‡ä»¶")
    
    gitignore_path = Path(__file__).parent.parent / ".gitignore"
    
    if gitignore_path.exists():
        with open(gitignore_path, 'r', encoding='utf-8') as f:
            gitignore_content = f.read()
        
        # æ˜¾ç¤ºæ–‡ä»¶å†…å®¹
        st.code(gitignore_content, language='text', line_numbers=True)
        
        # æä¾›ä¸‹è½½
        st.download_button(
            label="â¬‡ï¸ ä¸‹è½½ .gitignore æ–‡ä»¶",
            data=gitignore_content.encode('utf-8'),
            file_name=".gitignore",
            mime="text/plain"
        )
        
        # è¯´æ˜ä¿¡æ¯
        st.info("""
        ### .gitignore ä½¿ç”¨è¯´æ˜
        
        è¿™ä¸ª `.gitignore` æ–‡ä»¶åŒ…å«äº†ä»¥ä¸‹å†…å®¹ï¼š
        
        - Python ç¼–è¯‘æ–‡ä»¶å’Œç¼“å­˜
        - PyTorch æ¨¡å‹æƒé‡æ–‡ä»¶
        - YOLO ç‰¹å®šæ–‡ä»¶ï¼ˆruns/, weights/ ç­‰ï¼‰
        - è™šæ‹Ÿç¯å¢ƒç›®å½•
        - IDE é…ç½®æ–‡ä»¶ï¼ˆVSCode, PyCharm ç­‰ï¼‰
        - æ•°æ®å’Œç»“æœæ–‡ä»¶
        - ä¸´æ—¶æ–‡ä»¶å’Œæ—¥å¿—
        
        ### å¦‚ä½•ä½¿ç”¨
        
        1. å°†æ­¤æ–‡ä»¶ä¿å­˜åˆ°ä½ çš„é¡¹ç›®æ ¹ç›®å½•
        2. Git ä¼šè‡ªåŠ¨å¿½ç•¥è¿™äº›æ–‡ä»¶
        3. ä¸ä¼šè¢«æäº¤åˆ°ç‰ˆæœ¬æ§åˆ¶ç³»ç»Ÿ
        
        ### Git ä¸‹è½½é¡¹ç›®
        
        å¦‚æœä½ æœ‰ Git ä»“åº“ï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å…‹éš†é¡¹ç›®ï¼š
        ```bash
        git clone <ä½ çš„ä»“åº“åœ°å€>
        cd yolov9_detection
        ```
        """)
    else:
        st.warning("æœªæ‰¾åˆ° .gitignore æ–‡ä»¶")
    
    # å…¶ä»–èµ„æºæ–‡ä»¶
    st.markdown("---")
    st.subheader("å…¶ä»–èµ„æº")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("""
        ### requirements.txt
        Python ä¾èµ–åŒ…åˆ—è¡¨
        """)
        
        requirements_path = Path(__file__).parent / "requirements.txt"
        if requirements_path.exists():
            with open(requirements_path, 'r', encoding='utf-8') as f:
                requirements_content = f.read()
            
            st.download_button(
                label="â¬‡ï¸ ä¸‹è½½ requirements.txt",
                data=requirements_content.encode('utf-8'),
                file_name="requirements.txt",
                mime="text/plain",
                key="download_requirements"
            )
    
    with col2:
        st.markdown("""
        ### README.md
        é¡¹ç›®è¯´æ˜æ–‡æ¡£
        """)
        
        readme_path = Path(__file__).parent.parent / "README.md"
        if readme_path.exists():
            with open(readme_path, 'r', encoding='utf-8') as f:
                readme_content = f.read()
            
            st.download_button(
                label="â¬‡ï¸ ä¸‹è½½ README.md",
                data=readme_content.encode('utf-8'),
                file_name="README.md",
                mime="text/markdown",
                key="download_readme"
            )
    
    # é¡¹ç›®ç»“æ„
    st.markdown("---")
    st.subheader("é¡¹ç›®ç»“æ„")
    
    st.code("""
    yolov9_detection/
    â”œâ”€â”€ .gitignore              # Git å¿½ç•¥æ–‡ä»¶é…ç½®
    â”œâ”€â”€ README.md               # é¡¹ç›®è¯´æ˜
    â”œâ”€â”€ requirements.txt        # Python ä¾èµ–
    â”œâ”€â”€ detect.py              # æ£€æµ‹è„šæœ¬
    â”œâ”€â”€ train.py               # è®­ç»ƒè„šæœ¬
    â”œâ”€â”€ web_app/               # Web åº”ç”¨
    â”‚   â”œâ”€â”€ app.py            # Streamlit åº”ç”¨ä¸»æ–‡ä»¶
    â”‚   â”œâ”€â”€ requirements.txt  # Web åº”ç”¨ä¾èµ–
    â”‚   â””â”€â”€ run.sh            # å¯åŠ¨è„šæœ¬
    â”œâ”€â”€ data/                 # æ•°æ®é›†ç›®å½•
    â”œâ”€â”€ weights/              # æ¨¡å‹æƒé‡ç›®å½•
    â””â”€â”€ runs/                 # è®­ç»ƒå’Œæ£€æµ‹ç»“æœç›®å½•
    """, language='text')


def main():
    """ä¸»å‡½æ•°"""
    # ä¾§è¾¹æ 
    st.sidebar.title("ğŸ¯ YOLOv9 æ£€æµ‹ç³»ç»Ÿ")
    
    # æ¨¡å‹é€‰æ‹©
    st.sidebar.subheader("âš™ï¸ è®¾ç½®")
    model_size = st.sidebar.selectbox(
        "é€‰æ‹©æ¨¡å‹",
        options=['yolov8n.pt', 'yolov8s.pt', 'yolov8m.pt', 'yolov8l.pt', 'yolov8x.pt'],
        index=1,
        help="n=æœ€å¿«, s=å¿«, m=ä¸­ç­‰, l=æ…¢, x=æœ€æ…¢ä½†æœ€å‡†ç¡®"
    )
    
    conf_threshold = st.sidebar.slider("ç½®ä¿¡åº¦é˜ˆå€¼", 0.0, 1.0, 0.25)
    iou_threshold = st.sidebar.slider("IOUé˜ˆå€¼", 0.0, 1.0, 0.45)
    
    # é‡æ–°åŠ è½½æ£€æµ‹å™¨
    if 'detector' not in st.session_state or st.sidebar.button("é‡æ–°åŠ è½½æ¨¡å‹"):
        st.sidebar.info("æ­£åœ¨åŠ è½½æ¨¡å‹...")
        detector = load_detector(
            weights=model_size,
            conf=conf_threshold,
            iou=iou_threshold
        )
        if detector:
            st.session_state['detector'] = detector
            st.sidebar.success("æ¨¡å‹åŠ è½½æˆåŠŸ!")
    
    detector = st.session_state.get('detector')
    
    if not detector:
        st.error("æ¨¡å‹æœªåŠ è½½ï¼Œè¯·ç­‰å¾…æ¨¡å‹åŠ è½½å®Œæˆ")
        st.stop()
    
    # é¡µé¢å¯¼èˆª
    st.sidebar.markdown("---")
    st.sidebar.subheader("ğŸ“‹ åŠŸèƒ½å¯¼èˆª")
    
    page = st.sidebar.radio(
        "é€‰æ‹©åŠŸèƒ½",
        ["ğŸ“· å›¾ç‰‡æ£€æµ‹", "ğŸ¬ è§†é¢‘æ£€æµ‹", "ğŸ“¹ å®æ—¶æ‘„åƒå¤´", "ğŸ“ æ‰¹é‡æ£€æµ‹", "ğŸ“¦ é¡¹ç›®èµ„æº"]
    )
    
    # ä¸»å†…å®¹
    st.title("ğŸ¯ YOLOv9 å®æ—¶æ£€æµ‹ç³»ç»Ÿ")
    st.markdown("---")
    
    # æ ¹æ®é€‰æ‹©æ˜¾ç¤ºä¸åŒé¡µé¢
    if page == "ğŸ“¦ é¡¹ç›®èµ„æº":
        # èµ„æºé¡µé¢ä¸éœ€è¦åŠ è½½æ£€æµ‹å™¨
        resources_page()
    else:
        # å…¶ä»–é¡µé¢éœ€è¦æ£€æµ‹å™¨
        detector = st.session_state.get('detector')
        
        if not detector:
            st.error("æ¨¡å‹æœªåŠ è½½ï¼Œè¯·ç­‰å¾…æ¨¡å‹åŠ è½½å®Œæˆ")
            st.stop()
        
        if page == "ğŸ“· å›¾ç‰‡æ£€æµ‹":
            image_detection_page(detector)
        elif page == "ğŸ¬ è§†é¢‘æ£€æµ‹":
            video_detection_page(detector)
        elif page == "ğŸ“¹ å®æ—¶æ‘„åƒå¤´":
            webcam_detection_page(detector)
        elif page == "ğŸ“ æ‰¹é‡æ£€æµ‹":
            batch_detection_page(detector)
    
    # é¡µè„š
    st.sidebar.markdown("---")
    st.sidebar.markdown("""
    ### å…³äº
    åŸºäºYOLOv9çš„å®æ—¶ç›®æ ‡æ£€æµ‹ç³»ç»Ÿ
    
    æ”¯æŒçš„åŠŸèƒ½ï¼š
    - âœ… å›¾ç‰‡æ£€æµ‹
    - âœ… è§†é¢‘æ£€æµ‹
    - âœ… æ‰¹é‡å¤„ç†
    - âœ… å¤šç§æ¨¡å‹é€‰æ‹©
    """)


if __name__ == "__main__":
    main()
